import json
import os

class CalculatorFactory:
    @staticmethod
    def from_config(model_name, config_json="Calculator_defs.json"):
        """
        ä»æ¨¡å‹åå’Œjsoné…ç½®æ–‡ä»¶ï¼Œè¿”å›ASEå…¼å®¹çš„calculatorå¯¹è±¡ã€‚
        """
        with open(config_json) as f:
            models = json.load(f)
        assert model_name in models, f"Model '{model_name}' not found in {config_json}!"

        entry = models[model_name]
        arch = entry["arch"]
        model_path = entry["path"].replace("$HOME", os.environ.get("HOME", ""))
        try:
            import torch
            device = "cuda" if torch.cuda.is_available() else "cpu"
        except ImportError:
            device = "cpu"

        if arch == "sevenn":
            from sevenn.calculator import SevenNetCalculator
            return SevenNetCalculator(model=model, device=cuda)
        elif arch == "mace_mp":
            from mace.calculators import mace_mp
            return mace_mp(model=model_path, dispersion=True, device=device)
        
        elif arch == "lmy":
            import sys
            import torch # ç¡®ä¿å¼•å…¥ torch
            sys.path.append("no_topology") # ç¡®ä¿è·¯å¾„èƒ½æ‰¾åˆ° src
            
            from src.models import HTGPModel
            from src.utils import HTGP_Calculator, HTGPConfig
            
            # 1. é…ç½® (ä¿æŒä½ åŸæ¥çš„)
            config = HTGPConfig(
                num_atom_types=55, 
                hidden_dim=64, 
                num_layers=3, 
                cutoff=6.0, 
                num_rbf=10,
                use_L0=True, 
                use_L1=True,
                use_L2=True, 
                use_gating=True, 
                use_long_range=False
            )
            
            # 2. æ­å»ºéª¨æ¶
            model = HTGPModel(config)
            
            # ---------------------------------------------------------
            # ğŸ”¥ğŸ”¥ğŸ”¥ ä¿®æ­£å¼€å§‹ï¼šåŠ è½½æƒé‡ ğŸ”¥ğŸ”¥ğŸ”¥
            # ---------------------------------------------------------
            print(f"Loading weights from: {model_path}")
            
            # A. åŠ è½½æ–‡ä»¶
            state_dict = torch.load(model_path, map_location=device)
            
            # B. å¦‚æœä¿å­˜çš„æ˜¯ checkpoint å­—å…¸ï¼Œæå– model_state_dict
            # (é˜²æ­¢ä½ ä¹‹åæ”¹äº†ä¿å­˜æ ¼å¼ï¼Œè¿™é‡Œåšä¸€ä¸ªå…¼å®¹)
            if isinstance(state_dict, dict) and 'model_state_dict' in state_dict:
                state_dict = state_dict['model_state_dict']
            
            # C. å¤„ç† DDP çš„ "module." å‰ç¼€
            new_state_dict = {}
            for k, v in state_dict.items():
                if k.startswith('module.'):
                    new_state_dict[k[7:]] = v # å»æ‰ module.
                else:
                    new_state_dict[k] = v
            
            # D. å°†æƒé‡è½½å…¥æ¨¡å‹
            try:
                model.load_state_dict(new_state_dict, strict=True)
                print("âœ… Weights loaded successfully!")
            except RuntimeError as e:
                print(f"âŒ Weight loading failed: {e}")
                # å¦‚æœ strict=True å¤±è´¥ï¼Œå¯ä»¥å°è¯• strict=Falseï¼Œæˆ–è€…æ£€æŸ¥ config æ˜¯å¦åŒ¹é…
                raise e 
            
            # ---------------------------------------------------------
            # ğŸ”¥ğŸ”¥ğŸ”¥ ä¿®æ­£ç»“æŸ ğŸ”¥ğŸ”¥ğŸ”¥
            # ---------------------------------------------------------

            # 3. è¿”å› Calculator
            return HTGP_Calculator(model, cutoff=6.0, device=device)

        # ...å¯ä»¥ç»§ç»­æ‰©å±•æ›´å¤šæ¨¡å‹
        else:
            raise NotImplementedError(f"Model arch '{arch}' not supported!")
