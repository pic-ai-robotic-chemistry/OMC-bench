import torch
import os
from torch.utils.data import Dataset
import h5py
import numpy as np
from torch_geometric.data import Data

class ChunkedSmartDataset(Dataset):
    def __init__(self, data_dir, metadata_file, cache_size=16, rank=0, world_size=1):
        """
        :param data_dir: æ•°æ®ç›®å½•
        :param metadata_file: å…ƒæ•°æ®æ–‡ä»¶å (e.g., 'train_metadata.pt')
        :param cache_size: å†…å­˜ä¸­æœ€å¤šç¼“å­˜å¤šå°‘ä¸ª .pt æ–‡ä»¶å— (æ ¹æ®ä½ çš„å†…å­˜å¤§å°è°ƒæ•´)
        """
        self.data_dir = data_dir
        meta_path = os.path.join(data_dir, metadata_file)
        
        
        self.metadata = torch.load(meta_path, weights_only=False)
        if rank == 0:
            print(f"ğŸ“‚ Loading metadata from {meta_path}...")

        # ç®€å•çš„ LRU ç¼“å­˜
        self.cache = {} 
        self.cache_keys = [] # è®°å½•é¡ºåº
        self.max_cache = cache_size

    def _load_chunk(self, filename):
        # 1. å‘½ä¸­ç¼“å­˜
        if filename in self.cache:
            # ç§»åˆ°é˜Ÿå°¾è¡¨ç¤ºæœ€è¿‘ä½¿ç”¨
            self.cache_keys.remove(filename)
            self.cache_keys.append(filename)
            return self.cache[filename]
        
        # 2. æœªå‘½ä¸­ï¼ŒåŠ è½½æ–°æ–‡ä»¶
        full_path = os.path.join(self.data_dir, filename)
        try:
            chunk_data = torch.load(full_path, weights_only=False)
        except Exception as e:
            print(f"âŒ Error loading chunk {filename}: {e}")
            return [] # è¿”å›ç©ºåˆ—è¡¨é˜²æ­¢å´©æºƒ

        # 3. æ›´æ–°ç¼“å­˜
        if len(self.cache_keys) >= self.max_cache:
            # ç§»é™¤æœ€ä¹…æœªä½¿ç”¨çš„
            oldest = self.cache_keys.pop(0)
            del self.cache[oldest]
            
        self.cache[filename] = chunk_data
        self.cache_keys.append(filename)
        return chunk_data

    def __getitem__(self, idx):
        # 1. æŸ¥å­—å…¸
        info = self.metadata[idx]
        file_name = info['file_path']
        inner_idx = info['index_in_file']
        
        # 2. æ‹¿æ•°æ® (å¸¦ç¼“å­˜)
        chunk_data = self._load_chunk(file_name)
        data = chunk_data[inner_idx]

        # ========================================================
        # ğŸ”¥ å¼ºåˆ¶ç±»å‹ä¿®æ­£ (ä¿æŒä½ åŸæœ‰çš„é€»è¾‘)
        # ========================================================
        # --- A. ç´¢å¼•ç±» Int64 ---
        if hasattr(data, 'edge_index') and data.edge_index is not None:
            data.edge_index = data.edge_index.to(torch.long)
        if hasattr(data, 'z') and data.z is not None:
            data.z = data.z.to(torch.long)
        if hasattr(data, 'edge_type') and data.edge_type is not None:
            data.edge_type = data.edge_type.to(torch.long)

        # --- B. æ•°å€¼ç±» Float32 ---
        if hasattr(data, 'pos') and data.pos is not None and data.pos.dtype != torch.float32:
            data.pos = data.pos.to(torch.float32)
        
        if hasattr(data, 'cell') and data.cell is not None and data.cell.dtype != torch.float32:
            data.cell = data.cell.to(torch.float32)

        # å¤„ç† shifts
        if hasattr(data, 'shifts_int') and data.shifts_int is not None and data.shifts_int.dtype != torch.float32:
            data.shifts_int = data.shifts_int.to(torch.float32)
            # del data.shifts_int # å¯åˆ å¯ä¸åˆ ï¼ŒPyG Collate ä¼šå¿½ç•¥ä¸è®¤è¯†çš„å­—æ®µ
        elif hasattr(data, 'shifts') and data.shifts is not None and data.shifts.dtype != torch.float32:
            data.shifts = data.shifts.to(torch.float32)

        if hasattr(data, 'y') and data.y is not None and data.y.dtype != torch.float32:
            data.y = data.y.to(torch.float32)
        if hasattr(data, 'force') and data.force is not None and data.force.dtype != torch.float32:
            data.force = data.force.to(torch.float32)
        if hasattr(data, 'stress') and data.stress is not None and data.stress.dtype != torch.float32:
            data.stress = data.stress.to(torch.float32)

        return data

    def __len__(self):
        return len(self.metadata)
    

class ChunkedSmartDataset_h5(Dataset):
    def __init__(self, data_dir, metadata_file, rank=0, world_size=1):
        """
        :param data_dir: æ•°æ®ç›®å½•
        :param metadata_file: å…ƒæ•°æ®æ–‡ä»¶å (e.g., 'train_metadata.pt')
        """
        self.data_dir = data_dir
        meta_path = os.path.join(data_dir, metadata_file)
        
        # Metadata ä¾ç„¶æ˜¯å¿…éœ€çš„ï¼Œå› ä¸ºå®ƒå‘Šè¯‰æˆ‘ä»¬è¦å»å“ªä¸ªæ–‡ä»¶æ‰¾ç¬¬ N ä¸ªæ ·æœ¬
        # æ³¨æ„ï¼šä½ éœ€è¦ç¡®ä¿ metadata é‡Œçš„ 'file_path' åç¼€ç°åœ¨æ˜¯ .h5 è€Œä¸æ˜¯ .pt
        # å¦‚æœä½ æ²¡é‡æ–°ç”Ÿæˆ metadataï¼Œå¯èƒ½éœ€è¦åœ¨è¿™é‡Œæ‰‹åŠ¨ replace('.pt', '.h5')
        self.metadata = torch.load(meta_path, weights_only=False)
        
        if rank == 0:
            print(f"ğŸ“‚ Loading metadata from {meta_path}...")
            
        # ç§»é™¤ Cacheã€‚HDF5 çš„ OS Page Cache å·²ç»è¶³å¤Ÿé«˜æ•ˆï¼Œ
        # ä¸”é¿å…äº† Python å¯¹è±¡çš„å†…å­˜å¼€é”€ã€‚

    def __getitem__(self, idx):
        # 1. æŸ¥å­—å…¸
        info = self.metadata[idx]
        file_name = info['file_path']
        
        # å…¼å®¹æ€§å¤„ç†ï¼šå¦‚æœä½ æ²¡é‡æ–°ç”Ÿæˆ metadataï¼Œè¿™é‡Œå¼ºåˆ¶ä¿®æ­£åç¼€
        if file_name.endswith('.pt'):
            file_name = file_name.replace('.pt', '.h5')
            
        inner_idx = info['index_in_file'] # è¿™æ˜¯è¯¥å›¾åœ¨ chunk ä¸­çš„ç¬¬å‡ ä¸ª
        full_path = os.path.join(self.data_dir, file_name)

        # 2. æ‰“å¼€ H5 å¹¶åˆ‡ç‰‡è¯»å– (Lazy Loading)
        # è¿™ç§æ¨¡å¼ä¸‹ï¼Œä¸è¦æŠŠ f å­˜ä¸º self.fï¼Œå¦åˆ™å¤šè¿›ç¨‹ DataLoader ä¼šæ­»é”
        # æ¯æ¬¡ getitem æ‰“å¼€å¹¶è¯»å–æ˜¯å®‰å…¨çš„ï¼Œå¯¹äº SSD æ¥è¯´å¼€é”€å¾ˆå°
        try:
            with h5py.File(full_path, 'r') as f:
                # è·å–æŒ‡é’ˆä½ç½®
                a_start = f['atom_ptr'][inner_idx]
                a_end = f['atom_ptr'][inner_idx + 1]
                
                e_start = f['edge_ptr'][inner_idx]
                e_end = f['edge_ptr'][inner_idx + 1]
                
                # è¯»å–æ•°æ® (Numpy Slicing) - åªæœ‰è¿™ä¸€åˆ»æ‰ä¼šå‘ç”ŸçœŸæ­£çš„ IO
                # è¿™é‡Œçš„ [()] æ˜¯ h5py è¯»å–å…¨éƒ¨/æ ‡é‡çš„è¯­æ³•ï¼Œåˆ‡ç‰‡åˆ™ç›´æ¥ç”¨ [start:end]
                z = torch.from_numpy(f['z'][a_start:a_end].astype(np.int64)) # PyTorch Embedding é€šå¸¸éœ€è¦ Long
                pos = torch.from_numpy(f['pos'][a_start:a_end])
                force = torch.from_numpy(f['force'][a_start:a_end])
                
                edge_index = torch.from_numpy(f['edge_index'][:, e_start:e_end].astype(np.int64))
                shifts_int = torch.from_numpy(f['shifts_int'][e_start:e_end].astype(np.float32)) # è½¬ float
                
                # Graph çº§å±æ€§
                y = torch.from_numpy(f['y'][inner_idx])
                cell = torch.from_numpy(f['cell'][inner_idx])
                
                stress = None
                if f.attrs['has_stress']:
                    stress = torch.from_numpy(f['stress'][inner_idx])

            # 3. ç»„è£… PyG Data
            data = Data(
                z=z,
                pos=pos,
                cell=cell,
                edge_index=edge_index,
                shifts_int=shifts_int,
                y=y,
                force=force
            )
            
            if stress is not None:
                data.stress = stress

            # 4. æ•°æ®ç±»å‹å¾®è°ƒ (å’Œä½ åŸæ¥çš„é€»è¾‘ä¸€è‡´)
            # æ³¨æ„ï¼šä¸Šé¢è¯»å–æ—¶æˆ‘å·²ç»å°½é‡è½¬æ¢äº†ï¼Œè¿™é‡Œä½œä¸ºåŒé‡ä¿é™©
            if data.pos.dtype != torch.float32: data.pos = data.pos.to(torch.float32)
            if data.y.dtype != torch.float32: data.y = data.y.to(torch.float32)

            return data

        except Exception as e:
            # å®¹é”™å¤„ç†
            print(f"âŒ Error reading {full_path} at idx {inner_idx}: {e}")
            # è¿”å›ä¸€ä¸ªç©ºçš„æˆ–è€… Dummy æ•°æ®ï¼Œé¿å…è®­ç»ƒä¸­æ–­ (æ ¹æ®éœ€è¦è°ƒæ•´)
            return Data()

    def __len__(self):
        return len(self.metadata)